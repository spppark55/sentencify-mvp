import os
import json
from collections import Counter, defaultdict
import math
from pathlib import Path
from typing import Dict, List, Any
from pymongo import MongoClient
import numpy as np

# ì„¤ì •
MONGO_URI = os.getenv("MONGO_URI", "mongodb://localhost:27017")
DB_NAME = os.getenv("MONGO_DB_NAME", "sentencify")
COLLECTION_NAME = "raw_corporate_data"
OUTPUT_FILE = Path("docs/phase3/data_analysis_report.md")

def connect_db():
    client = MongoClient(MONGO_URI)
    return client[DB_NAME]

def calculate_entropy(counter: Counter) -> float:
    """
    í–‰ë™ì˜ ë¶ˆí™•ì‹¤ì„±(Entropy) ê³„ì‚°.
    ê°’ì´ 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ í•œ ê°€ì§€ í–‰ë™ë§Œ ë°˜ë³µ(ì¼ê´€ì„± ë†’ìŒ).
    ê°’ì´ ë†’ì„ìˆ˜ë¡ í–‰ë™ì´ ë¬´ì‘ìœ„(Random).
    """
    total = sum(counter.values())
    if total == 0:
        return 0.0
    entropy = 0.0
    for count in counter.values():
        p = count / total
        entropy -= p * math.log2(p)
    return entropy

def run_eda():
    db = connect_db()
    collection = db[COLLECTION_NAME]
    
    print(f"[EDA] Analyzing collection '{COLLECTION_NAME}'...")
    
    # 1. ì‚¬ìš©ìë³„ í†µê³„ ì§‘ê³„
    user_stats = defaultdict(lambda: {
        "actions": 0,
        "categories": Counter(),
        "intensities": Counter(),
        "languages": Counter(),
        "prompts": []
    })
    
    # correction_history (User Prompt í¬í•¨)
    for doc in collection.find({"_source_file": "correction_history.json"}):
        uid = doc.get("user")
        if not uid: continue
        
        user_stats[uid]["actions"] += 1
        if f := doc.get("field"): user_stats[uid]["categories"][f] += 1
        if i := doc.get("intensity"): user_stats[uid]["intensities"][i] += 1
        if p := doc.get("user_prompt"): 
             if len(p) < 100: user_stats[uid]["prompts"].append(p)

    # event_raw (ì‹¤í–‰ ë¡œê·¸)
    for doc in collection.find({"_source_file": "event_raw.json", "event": "event_editor_run_paraphrasing"}):
        uid = doc.get("distinct_id")
        if not uid: continue
        
        user_stats[uid]["actions"] += 1
        if f := doc.get("field"): user_stats[uid]["categories"][f] += 1
        if i := doc.get("maintenance"): user_stats[uid]["intensities"][i] += 1 # maintenance -> intensity ë§¤í•‘
        if l := doc.get("target_language"): user_stats[uid]["languages"][l] += 1
    
    total_users = len(user_stats)
    if total_users == 0:
        print("[EDA] No users found. Please check if data is imported.")
        return

    print(f"[EDA] Found {total_users} distinct users.")

    # 2. ë©”íŠ¸ë¦­ ê³„ì‚°
    action_counts = [s["actions"] for s in user_stats.values()]
    avg_actions = np.mean(action_counts)
    median_actions = np.median(action_counts)
    heavy_users = len([c for c in action_counts if c >= 10])
    
    # ì¼ê´€ì„±(Consistency) ë¶„ì„: Category Entropy
    # Entropyê°€ 0.5 ì´í•˜ì¸ ìœ ì €(ìƒë‹¹íˆ ì¼ê´€ëœ ìœ ì €)ì˜ ë¹„ìœ¨
    consistent_users = 0
    for uid, stats in user_stats.items():
        if stats["actions"] < 5: continue # í™œë™ ì ì€ ìœ ì € ì œì™¸
        e = calculate_entropy(stats["categories"])
        if e < 0.5: # ê±°ì˜ í•œë‘ ê°€ì§€ ì¹´í…Œê³ ë¦¬ë§Œ ì”€
            consistent_users += 1
    
    valid_users_count = len([u for u in user_stats.values() if u["actions"] >= 5])
    consistency_ratio = (consistent_users / valid_users_count * 100) if valid_users_count > 0 else 0

    # Prompt ë¶„ì„
    all_prompts = []
    for s in user_stats.values():
        all_prompts.extend(s["prompts"])
    prompt_keywords = Counter(" ".join(all_prompts).split()).most_common(20)

    # 3. ë¦¬í¬íŠ¸ ì‘ì„±
    report_content = f"""# ğŸ“Š Phase 3 Data Analysis Report

> **Generated by:** `scripts/phase3/step1_eda.py`
> **Source Collection:** `{COLLECTION_NAME}`

## 1. User Statistics
*   **Total Users:** {total_users}
*   **Action Distribution:** Mean {avg_actions:.1f}, Median {median_actions:.1f}
*   **Heavy Users (>= 10 actions):** {heavy_users} ({heavy_users/total_users*100:.1f}%)
*   **Valid Analysis Target (>= 5 actions):** {valid_users_count}

## 2. Behavioral Consistency
*   **Hypothesis:** Do users stick to specific categories?
*   **Consistent Users (Entropy < 0.5):** {consistent_users}
*   **Consistency Ratio:** **{consistency_ratio:.1f}%** of valid users show strong category preference.
    *   *(If > 50%, persona modeling based on category is valid.)*
    *   *(If < 20%, user behavior is highly random or context-dependent.)*

## 3. User Prompt Insights
*   **Total Prompts Collected:** {len(all_prompts)}
*   **Top Keywords:**
    {json.dumps(dict(prompt_keywords), indent=4, ensure_ascii=False)}

## 4. Persona Feasibility Conclusion
*(This section is to be filled by the engineer after reviewing the stats above.)*
"""
    
    # ë””ë ‰í† ë¦¬ ìƒì„± í™•ì¸
    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)
    
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        f.write(report_content)
        
    print(f"âœ… [Done] Report generated at {OUTPUT_FILE}")
    print(report_content)

if __name__ == "__main__":
    run_eda()
