#!/usr/bin/env python
"""
Phase 1.5 Integration Test ‚Äì verifies diff ‚Üí Macro ETL ‚Üí Redis ‚Üí adaptive scoring.

This script performs a detailed end-to-end test of the Macro Context feature.
It simulates a user creating, editing, and getting recommendations for a document,
verifying each step of the data pipeline.

Prerequisites:
- API server running at http://localhost:8000
- Redis, Qdrant, and other dependent services are running.
- OpenAI API key is configured on the server.
- `pip install requests redis`

Run: python scripts/phase1.5_test_integration.py
"""

from __future__ import annotations

import os
import sys
import time
from pathlib import Path
from typing import Any, Dict
import json

import requests
import redis

# --- Test Configuration ---
BASE_URL = os.getenv("API_BASE_URL", "http://localhost:8000")
USER_ID = os.getenv("INTEGRATION_TEST_USER", "integration_tester_macro")
REDIS_HOST = os.getenv("REDIS_HOST", "localhost")
REDIS_PORT = int(os.getenv("REDIS_PORT", "6379"))

# This text is clearly about a thesis/academic paper.
# We expect the Macro LLM to classify it as 'thesis'.
LONG_THESIS_TEXT = """
The empirical analysis of quantum chromodynamics (QCD) presents formidable challenges.
This paper introduces a novel lattice gauge theory simulation to probe non-perturbative phenomena.
Our methodology builds upon the stochastic quantization framework, incorporating a quasi-Hamiltonian
Monte Carlo algorithm to mitigate critical slowing-down. We present preliminary results for the
hadronic spectrum and the chiral condensate, which show strong agreement with experimental data from
the Relativistic Heavy Ion Collider (RHIC). The implications for understanding quark confinement and
asymptotic freedom are profound. We further discuss the systematic errors inherent in our finite-volume
simulation and propose a multi-grid approach for future refinements. The computational cost, while
significant, is justified by the unprecedented precision of our findings.
""" * 5 # Make it long enough to ensure high doc maturity


def _api_call(method: str, path: str, payload: Dict[str, Any] | None = None) -> Dict[str, Any]:
    """Wrapper for API requests."""
    url = f"{BASE_URL}{path}"
    try:
        if method.upper() == "POST":
            response = requests.post(url, json=payload, timeout=30)
        elif method.upper() == "PATCH":
            response = requests.patch(url, json=payload, timeout=30)
        elif method.upper() == "DELETE":
             response = requests.delete(url, params=payload, timeout=30)
        else:
            raise ValueError(f"Unsupported method: {method}")
        
        response.raise_for_status()
        # Handle cases where response body might be empty
        if response.status_code == 204 or not response.content:
            return {}
        return response.json()
    except requests.exceptions.RequestException as e:
        print(f"\n[ERROR] API call {method.upper()} {url} failed: {e}")
        print(f"Response body: {e.response.text if e.response else 'No response'}")
        raise

def print_step(title: str):
    """Prints a formatted step title."""
    print("\n" + "="*80)
    print(f"  {title}")
    print("="*80)

def main():
    """Main function to run the integration test."""
    doc_id = None
    redis_client = None
    try:
        # --- Setup ---
        print_step("SETUP: Connecting to Redis and preparing test")
        redis_client = redis.Redis(host=REDIS_HOST, port=REDIS_PORT, db=0, decode_responses=True)
        redis_client.ping()
        print(f"Successfully connected to Redis at {REDIS_HOST}:{REDIS_PORT}")

        print("Creating a new document...")
        create_resp = _api_call("POST", "/documents", {"user_id": USER_ID})
        doc_id = create_resp["doc_id"]
        print(f"Document created with doc_id: {doc_id}")

        # --- Step 1: Cold Start Recommendation (Verify Fallback) ---
        print_step("STEP 1: Cold Start - Verify P_doc Fallback")
        cold_req_payload = {
            "doc_id": doc_id,
            "user_id": USER_ID,
            "selected_text": "This is a very short text.",
            "context_prev": "",
            "context_next": "",
        }
        cold_resp = _api_call("POST", "/recommend", cold_req_payload)

        p_doc_cold = cold_resp.get("P_doc", {})
        p_rule_cold = cold_resp.get("P_rule", {})
        alpha_cold = cold_resp.get("applied_weight_doc", -1.0)

        print(f"Cold Recommendation Response (alpha={alpha_cold:.4f}):")
        print(f"  P_rule: {p_rule_cold}")
        print(f"  P_doc: {p_doc_cold}")
        
        assert alpha_cold < 0.1, f"Cold start alpha should be low, but got {alpha_cold}"
        assert p_doc_cold, "P_doc should not be empty in cold start (must use fallback)"
        if p_rule_cold:
             best_rule_category = max(p_rule_cold, key=p_rule_cold.get)
             assert best_rule_category in p_doc_cold, \
                f"P_doc fallback failed. Expected best P_rule category '{best_rule_category}' in P_doc."
        print("‚úÖ PASSED: P_doc correctly uses P_rule fallback on cold start.")

        # --- Step 2: Trigger Macro Context Generation ---
        print_step("STEP 2: Trigger Macro Analysis")
        print("Updating document with long 'thesis' text to trigger Macro ETL...")
        _api_call("PATCH", f"/documents/{doc_id}", {"user_id": USER_ID, "latest_full_text": LONG_THESIS_TEXT})
        
        print("Waiting 10 seconds for the background task (Macro LLM analysis) to complete...")
        time.sleep(10)

        # --- Step 3: Verify Redis Cache Creation ---
        print_step("STEP 3: Verify Redis Cache Creation")
        macro_cache_key = f"macro_context:{doc_id}"
        cached_data_json = redis_client.get(macro_cache_key)

        assert cached_data_json, f"Macro context cache key '{macro_cache_key}' not found in Redis."
        print("Found cache key in Redis.")

        cached_data = json.loads(cached_data_json)
        print("Successfully parsed cache data from Redis:")
        print(json.dumps(cached_data, indent=2))

        assert cached_data["doc_id"] == doc_id
        
        # Allow for some flexibility in LLM classification
        expected_categories = ["thesis", "report"]
        actual_category = cached_data.get("macro_category_hint")
        assert actual_category in expected_categories, \
            f"Expected category to be one of {expected_categories}, but LLM classified it as '{actual_category}'"
        print(f"‚úÖ PASSED: Redis cache created with an acceptable category hint ('{actual_category}').")

        # --- Step 4: Warm Recommendation (Verify P_doc Application) ---
        print_step("STEP 4: Warm Start - Verify P_doc Application in Recommendation")
        warm_req_payload = {
            "doc_id": doc_id,
            "user_id": USER_ID,
            "selected_text": "This paper introduces a novel lattice gauge theory simulation.",
            "context_prev": "The empirical analysis of quantum chromodynamics (QCD) presents formidable challenges.",
            "context_next": "Our methodology builds upon the stochastic quantization framework.",
        }
        warm_resp = _api_call("POST", "/recommend", warm_req_payload)

        p_doc_warm = warm_resp.get("P_doc", {})
        alpha_warm = warm_resp.get("applied_weight_doc", -1.0)
        
        print(f"Warm Recommendation Response (alpha={alpha_warm:.4f}):")
        print(f"  P_doc: {p_doc_warm}")

        assert alpha_warm > alpha_cold, f"Warm alpha ({alpha_warm}) should be greater than cold alpha ({alpha_cold})."
        
        # Dynamically check against the category returned by the LLM
        assert actual_category in p_doc_warm, f"P_doc in warm response must reflect the cached '{actual_category}' hint."
        assert p_doc_warm[actual_category] > 0.9, f"The '{actual_category}' score in P_doc should be dominant."
        print("‚úÖ PASSED: P_doc correctly applied from cache with increased alpha.")


    except Exception as e:
        print(f"\n‚ùå TEST FAILED: An unexpected error occurred: {e}")
        # Add traceback for debugging
        import traceback
        traceback.print_exc()
        sys.exit(1)

    finally:
        # --- Cleanup ---
        if doc_id:
            print_step("CLEANUP: Deleting test document")
            try:
                _api_call("DELETE", f"/documents/{doc_id}", {"user_id": USER_ID})
                print(f"Successfully deleted document: {doc_id}")
            except Exception as e:
                print(f"[WARN] Failed to delete test document {doc_id}: {e}")
    
    print("\nüéâüéâüéâ ALL INTEGRATION TESTS PASSED! üéâüéâüéâ")


if __name__ == "__main__":
    main()