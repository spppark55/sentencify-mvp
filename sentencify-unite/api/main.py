from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
import hashlib
import json
import os
from pathlib import Path
from typing import Dict, Optional, List
import uuid
from datetime import datetime, timezone

# ğŸ’¡ [ì¶”ê°€]: ë™ê¸° í•¨ìˆ˜ë¥¼ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰í•˜ì—¬ ë©”ì¸ ì„œë²„ ë©ˆì¶¤ ë°©ì§€
from starlette.concurrency import run_in_threadpool 

from fastapi import FastAPI, HTTPException
# Kafka ê´€ë ¨ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šë‹¤ë©´ pip install kafka-python ì„ ì¶”ê°€ë¡œ í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# try-exceptë¡œ ê°ì‹¸ì„œ Kafkaê°€ ì—†ì–´ë„ ì„œë²„ê°€ ì‹œì‘ë˜ê²Œ í•©ë‹ˆë‹¤.
try:
    from kafka import KafkaProducer 
    from kafka.errors import KafkaError # ì—ëŸ¬ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì„í¬íŠ¸
except ImportError:
    KafkaProducer = None
    print("Warning: KafkaProducer not available. Kafka logging is disabled.")

from pydantic import BaseModel, Field

# ----------------------------------------------------------------------
# ëª¨ë“ˆ ì„í¬íŠ¸
from api.app.models.kobert_classifier import get_p_rule
from api.app.models.vector_retriever import get_p_vec
from api.app.models.gemini_corrector import generate_correction
# ----------------------------------------------------------------------


class RecommendRequest(BaseModel):
    doc_id: str = Field(..., description="ë¬¸ì„œ ê³ ìœ  ID")
    user_id: str = Field(..., description="ì‚¬ìš©ì ê³ ìœ  ID")
    selected_text: str = Field(..., description="ì‚¬ìš©ìê°€ ì„ íƒ(ë“œë˜ê·¸)í•œ ì›ë¬¸")
    context_prev: Optional[str] = Field(None, description="ì„ íƒ ë¬¸ì¥ ì´ì „ ë¬¸ë§¥")
    context_next: Optional[str] = Field(None, description="ì„ íƒ ë¬¸ì¥ ì´í›„ ë¬¸ë§¥")
    field: Optional[str] = Field(None, description="ì‚¬ìš©ìê°€ ì§ì ‘ ì§€ì •í•œ ë¶„ì•¼ (ìˆ˜ë™ ì˜µì…˜)")
    language: Optional[str] = Field(None, description="ì–¸ì–´ (ko/en)")
    intensity: Optional[str] = Field(None, description="ê°•ë„ (moderate/high)")
    user_prompt: Optional[str] = Field(None, description="ì‚¬ìš©ìê°€ ì§ì ‘ ì…ë ¥í•œ í”„ë¡¬í”„íŠ¸")


class RecommendOption(BaseModel):
    # --- 2. ì‘ë‹µ ëª¨ë¸ì— í…ìŠ¤íŠ¸ í•„ë“œ ì¶”ê°€ ---
    text: str = Field(..., description="Geminiê°€ ìƒì„±í•œ ì‹¤ì œ êµì • ë¬¸ì¥")
    category: str = Field(..., description="ì ìš©ëœ ë¬¸ì¥ í˜•ì‹ ë¶„ë¥˜ (ì˜ˆ: thesis, email)")
    language: str
    intensity: str


class RecommendResponse(BaseModel):
    insert_id: str
    recommend_session_id: str
    reco_options: List[RecommendOption]
    P_rule: Dict[str, float]
    P_vec: Dict[str, float]
    context_hash: str
    model_version: str
    api_version: str
    schema_version: str
    embedding_version: str


app = FastAPI()

# ----------------------------------------------------
# CORS ì„¤ì • (5173, 5174 í¬íŠ¸ í—ˆìš©)
# ----------------------------------------------------
origins = [
    "http://localhost:3000",
    "http://127.0.0.1:3000",
    "http://localhost:5173",
    "http://127.0.0.1:5173",
    "http://localhost:5174",
    "http://127.0.0.1:5174",
    "*" # ê°œë°œ í¸ì˜ë¥¼ ìœ„í•´ ì™€ì¼ë“œì¹´ë“œ ì¶”ê°€
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ----------------------------------------------------


LOG_DIR = Path("logs")
KAFKA_BOOTSTRAP_SERVERS = os.getenv("KAFKA_BOOTSTRAP_SERVERS", "kafka:9092")
KAFKA_ENABLED = os.getenv("KAFKA_ENABLED", "true").lower() != "false"

_kafka_producer: KafkaProducer | None = None


def get_kafka_producer() -> KafkaProducer | None:
    global _kafka_producer
    if not KAFKA_ENABLED or KafkaProducer is None:
        return None
    if _kafka_producer is not None:
        return _kafka_producer
    try:
        # FastAPI ì‹œì‘ ì‹œ í•œë²ˆë§Œ ì‹œë„í•˜ë„ë¡ ìˆ˜ì •
        _kafka_producer = KafkaProducer(
            bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
            value_serializer=lambda v: json.dumps(v, ensure_ascii=False).encode("utf-8"),
            api_version=(0, 10, 1), # ì ì ˆí•œ Kafka API ë²„ì „ ì§€ì •
            # ğŸ’¡ [í•µì‹¬ ìˆ˜ì • 1]: ì—°ê²° íƒ€ì„ì•„ì›ƒì„ 1ì´ˆë¡œ ì„¤ì • (60ì´ˆ ëŒ€ê¸° ë°©ì§€)
            bootstrap_servers_timeout_ms=1000,
            request_timeout_ms=1000,
            metadata_max_age_ms=1000
        )
        print("Kafka Producer initialized successfully.")
    except Exception as e:
        print(f"Warning: Could not initialize Kafka Producer. Logs will only be stored locally. Error: {e}")
        _kafka_producer = None
    return _kafka_producer


def _now_iso() -> str:
    return datetime.now(timezone.utc).isoformat()


def build_context_full(prev: Optional[str], selected: str, next_: Optional[str]) -> str:
    parts = []
    if prev:
        parts.append(prev)
    parts.append(selected)
    if next_:
        parts.append(next_)
    return "\n".join(parts)


def build_context_hash(doc_id: str, context_full: str) -> str:
    payload = f"{doc_id}:{context_full}"
    return hashlib.sha256(payload.encode("utf-8")).hexdigest()


def append_jsonl(filename: str, payload: Dict) -> None:
    LOG_DIR.mkdir(parents=True, exist_ok=True)
    path = LOG_DIR / filename
    try:
        with path.open("a", encoding="utf-8") as f:
            f.write(json.dumps(payload, ensure_ascii=False) + "\n")
    except Exception as e:
        print(f"Error writing to local log file {filename}: {e}")


# ğŸ’¡ [í•µì‹¬ ìˆ˜ì • 2]: Kafka ì „ì†¡ì„ ë‹´ë‹¹í•˜ëŠ” ë™ê¸° í•¨ìˆ˜ ë¶„ë¦¬
def _send_kafka_sync(topic: str, payload: Dict):
    producer = get_kafka_producer()
    if producer is not None:
        try:
            # ë¹„ë™ê¸° ì „ì†¡ (fire-and-forget). ê²°ê³¼ë¥¼ ê¸°ë‹¤ë¦¬ì§€ ì•ŠìŒ (.get() ì œê±°)
            producer.send(topic, value=payload)
        except Exception as e:
            print(f"Error sending {topic} event to Kafka: {e}")

# ğŸ’¡ [í•µì‹¬ ìˆ˜ì • 3]: APIì—ì„œ í˜¸ì¶œí•  ë¹„ë™ê¸° ë˜í¼ í•¨ìˆ˜ë“¤ (run_in_threadpool ì‚¬ìš©)
async def produce_a_event(payload: Dict) -> None:
    """ì¶”ì²œ ì˜µì…˜ (A) ë¡œê·¸ë¥¼ ìƒì„± ë° ì „ì†¡"""
    append_jsonl("a.jsonl", payload)
    await run_in_threadpool(_send_kafka_sync, "editor_recommend_options", payload)

async def produce_i_event(payload: Dict) -> None:
    """ëª¨ë¸ ìŠ¤ì½”ì–´ (I) ë¡œê·¸ë¥¼ ìƒì„± ë° ì „ì†¡"""
    append_jsonl("i.jsonl", payload)
    await run_in_threadpool(_send_kafka_sync, "model_score", payload)

async def produce_e_event(payload: Dict) -> None:
    """ë¬¸ë§¥ ë¸”ë¡ (E) ë¡œê·¸ë¥¼ ìƒì„± ë° ì „ì†¡"""
    append_jsonl("e.jsonl", payload)
    await run_in_threadpool(_send_kafka_sync, "context_block", payload)


@app.post("/recommend", response_model=RecommendResponse)
async def recommend(req: RecommendRequest) -> RecommendResponse:
    insert_id = str(uuid.uuid4())
    recommend_session_id = str(uuid.uuid4())

    print(f"--- [REQUEST] Received request for doc_id: {req.doc_id} ---")
    
    context_full = build_context_full(req.context_prev, req.selected_text, req.context_next)
    context_hash = build_context_hash(req.doc_id, context_full)
    
    # ----------------------------------------------------
    # --- KoBERT (P_rule) ë° Vector Search (P_vec) í˜¸ì¶œ ---
    # ----------------------------------------------------
    
    # KoBERT ëª¨ë¸ì„ í†µí•´ ë¬¸ë§¥ í˜•ì‹ ë¶„ë¥˜ í™•ë¥  (P_rule) íšë“
    try:
        # ğŸ’¡ [ìˆ˜ì •]: get_p_ruleì´ íŠœí”Œì„ ë°˜í™˜í•˜ë¯€ë¡œ ì–¸íŒ©í‚¹ ì‚¬ìš© (ì˜¤ë¥˜ í•´ê²°)
        p_rule, rule_model_version = get_p_rule(req.selected_text, req.user_id)
    except Exception as e:
        print(f"KoBERT get_p_rule error: {e}")
        p_rule = {}
        rule_model_version = "error"

    
    # Vector DB (Qdrant) ê²€ìƒ‰ì„ í†µí•´ ë¬¸ë§¥ í˜•ì‹ í™•ë¥  (P_vec) íšë“
    try:
        # ğŸ’¡ [ìˆ˜ì •]: get_p_vecì´ íŠœí”Œì„ ë°˜í™˜í•˜ë¯€ë¡œ ì–¸íŒ©í‚¹ ì‚¬ìš© (ì˜¤ë¥˜ í•´ê²°)
        p_vec, embed_version = get_p_vec(context_full, req.user_id)
    except Exception as e:
        print(f"Vector get_p_vec error: {e}")
        p_vec = {}
        embed_version = "error"
    
    # ----------------------------------------------------
    # --- P_ruleê³¼ P_vec ìœµí•© ë° ìµœì  í˜•ì‹ ê²°ì • ---
    # ----------------------------------------------------

    # P_ruleê³¼ P_vecì˜ ê°€ì¤‘ í‰ê·  ê³„ì‚° (í˜„ì¬ëŠ” 50:50)
    final_scores: Dict[str, float] = {}
    
    # ëª¨ë“  ì¹´í…Œê³ ë¦¬ë¥¼ ëŒ€ìƒìœ¼ë¡œ ìœµí•©
    all_categories = set(p_rule.keys()) | set(p_vec.keys())
    
    for k in all_categories:
        # ìœµí•© ë¹„ìœ¨ì€ í–¥í›„ A/B í…ŒìŠ¤íŠ¸ë‚˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ê´€ë¦¬ ê°€ëŠ¥
        score = 0.5 * p_rule.get(k, 0.0) + 0.5 * p_vec.get(k, 0.0)
        final_scores[k] = round(score, 4)

    # ìµœì¢… ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ ì¹´í…Œê³ ë¦¬ ì„ ì •
    best_category = max(final_scores, key=final_scores.get, default="general")
    language = req.language or "ko"
    intensity = req.intensity or "moderate"
    
    # ë§Œì•½ ì‚¬ìš©ìê°€ ìˆ˜ë™ìœ¼ë¡œ í˜•ì‹ì„ ì§€ì •í–ˆë‹¤ë©´ ê·¸ê²ƒì„ ìš°ì„  ì‚¬ìš©
    if req.field and req.field in all_categories:
        best_category = req.field

    # ----------------------------------------------------
    # --- Gemini (í•µì‹¬) í˜¸ì¶œ: êµì • í…ìŠ¤íŠ¸ ìƒì„± ---
    # ----------------------------------------------------
    
    # generate_correction í•¨ìˆ˜ëŠ” api/app/models/gemini_corrector.pyì— êµ¬í˜„ë  ì˜ˆì •ì…ë‹ˆë‹¤.
    try:
        # ğŸ’¡ [ìˆ˜ì •]: await í‚¤ì›Œë“œ ì¶”ê°€ (ë¹„ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰ ì˜¤ë¥˜ í•´ê²°)
        generated_options, gemini_model_version = await generate_correction(
            original_text=req.selected_text,
            context_full=context_full,
            best_category=best_category,
            language=language,
            intensity=intensity,
            user_prompt=req.user_prompt,
            user_id=req.user_id # ê°œì¸í™”ë¥¼ ìœ„í•´ user_id ì „ë‹¬
        )
    except Exception as e:
        print(f"Gemini generation error: {e}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ ì˜µì…˜ì„ ë°˜í™˜í•˜ì—¬ ì„œë¹„ìŠ¤ ì¤‘ë‹¨ ë°©ì§€
        generated_options = []
        gemini_model_version = "error"
        # ì„œë¹„ìŠ¤ ì•ˆì •ì„±ì„ ìœ„í•´ HTTPException ëŒ€ì‹  ë‚´ë¶€ ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶œë ¥ í›„ ì§„í–‰
        # raise HTTPException(status_code=500, detail=f"Correction generation failed: {e}") 

    # ìƒì„±ëœ í…ìŠ¤íŠ¸ ì˜µì…˜ì„ RecommendOption Pydantic ëª¨ë¸ë¡œ ë³€í™˜
    reco_options: List[RecommendOption] = [
        RecommendOption(
            text=opt.get("text", "ìƒì„± ì‹¤íŒ¨"), # ìƒì„±ëœ í…ìŠ¤íŠ¸
            category=opt.get("category", best_category), 
            language=language,
            intensity=intensity,
        ) 
        for opt in generated_options
    ]
    
    # ë§Œì•½ ì˜µì…˜ì´ ì—†ë‹¤ë©´ ê¸°ë³¸ ì˜µì…˜ì„ í•˜ë‚˜ ì¶”ê°€ (í”„ë¡ íŠ¸ì—”ë“œ ì˜¤ë¥˜ ë°©ì§€)
    if not reco_options:
        reco_options.append(RecommendOption(
            text=req.selected_text, 
            category=best_category, 
            language=language, 
            intensity=intensity
        ))


    # ----------------------------------------------------
    # --- ë¡œê·¸ ìƒì„± (A, I, E Event) ë° ì‘ë‹µ êµ¬ì„± ---
    # ----------------------------------------------------
    
    # ëª¨ë¸ ë²„ì „ ì •ë³´ ì—…ë°ì´íŠ¸
    model_version = f"KoBERT:{rule_model_version}, Vec:{embed_version}, Gemini:{gemini_model_version}"
    api_version = "v1"
    schema_version = "phase1_aie_v2" # í•„ë“œ ì¶”ê°€ë¡œ ë²„ì „ ì—…ë°ì´íŠ¸
    embedding_version = embed_version

    a_event = {
        "event": "editor_recommend_options",
        "insert_id": insert_id,
        "recommend_session_id": recommend_session_id,
        "doc_id": req.doc_id,
        "user_id": req.user_id,
        "selected_text": req.selected_text,
        "context_prev": req.context_prev,
        "context_next": req.context_next,
        "context_hash": context_hash,
        "context_full_preview": context_full[:500],
        # ì˜µì…˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•˜ì—¬ ë¡œê¹…
        "reco_options": [o.model_dump() for o in reco_options], 
        "P_rule": p_rule,
        "P_vec": p_vec,
        "model_version": model_version,
        "api_version": api_version,
        "schema_version": schema_version,
        "embedding_version": embedding_version,
        "created_at": _now_iso(),
    }
    # ğŸ’¡ [í•µì‹¬]: awaitì„ ì‚¬ìš©í•˜ì—¬ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œë¡œ ë¡œê·¸ ì „ì†¡ (ì„œë²„ ì•ˆ ë©ˆì¶¤)
    await produce_a_event(a_event)

    i_event = {
        "event": "model_score",
        "insert_id": str(uuid.uuid4()),
        "source_recommend_event_id": insert_id,
        "recommend_session_id": recommend_session_id,
        "doc_id": req.doc_id,
        "user_id": req.user_id,
        "context_hash": context_hash,
        "P_rule": p_rule,
        "P_vec": p_vec,
        "model_version": model_version,
        "api_version": api_version,
        "schema_version": schema_version,
        "created_at": _now_iso(),
    }
    # ğŸ’¡ [í•µì‹¬]: awaitì„ ì‚¬ìš©í•˜ì—¬ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œë¡œ ë¡œê·¸ ì „ì†¡
    await produce_i_event(i_event)

    e_event = {
        "event": "context_block",
        "insert_id": str(uuid.uuid4()),
        "doc_id": req.doc_id,
        "user_id": req.user_id,
        "context_hash": context_hash,
        "context_full": context_full,
        "embedding_version": embedding_version,
        "created_at": _now_iso(),
    }
    # ğŸ’¡ [í•µì‹¬]: awaitì„ ì‚¬ìš©í•˜ì—¬ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œë¡œ ë¡œê·¸ ì „ì†¡
    await produce_e_event(e_event)

    return RecommendResponse(
        insert_id=insert_id,
        recommend_session_id=recommend_session_id,
        reco_options=reco_options,
        P_rule=p_rule,
        P_vec=p_vec,
        context_hash=context_hash,
        model_version=model_version,
        api_version=api_version,
        schema_version=schema_version,
        embedding_version=embedding_version,
    )